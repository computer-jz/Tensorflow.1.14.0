{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import collections\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 将词汇映射成词汇表"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#训练集数据文件\n",
    "RAW_DATA=\"data/simple-examples/data/ptb.train.txt\"\n",
    "#输出的词汇表文件\n",
    "VOCAB_OUTPUT=\"data/simple-examples/data/ptb.vocab\"\n",
    "\n",
    "#统计单词出现的频率\n",
    "counter=collections.Counter()\n",
    "with codecs.open(RAW_DATA,\"r\",\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        for word in line.strip().split():\n",
    "            counter[word]+=1\n",
    "\n",
    "\n",
    "#按照词频进行从大到小排序,转换成list\n",
    "sorted_word_to_cnt=sorted(counter.items(),key=itemgetter(1),reverse=True)\n",
    "sorted_words=[x[0] for x in sorted_word_to_cnt]\n",
    "\n",
    "#文本换行处加入句子结束符号\n",
    "sorted_words=[\"<eos>\"]+sorted_words\n",
    "\n",
    "with codecs.open(VOCAB_OUTPUT,'w','utf-8') as file_output:\n",
    "    for word in sorted_words:\n",
    "        file_output.write(word+'\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 将训练文件，测试文件等根据词汇文件转换为单词编号\n",
    "- 每个单词标号就是他们在词汇文件中的行号"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import sys\n",
    "VOCAB=\"data/simple-examples/data/ptb.vocab\"\n",
    "OUTPUT_DATA=\"data/simple-examples/data/ptb.train\"\n",
    "\n",
    "# 读取词汇表,并建立词汇到单词编号的映射\n",
    "with codecs.open(VOCAB, \"r\", \"utf-8\") as f_vocab:\n",
    "    vocab = [w.strip() for w in f_vocab.readlines()]\n",
    "word_to_id = {k: v for (k, v) in zip(vocab, range(len(vocab)))}\n",
    "\n",
    "\n",
    "# 如果出现了不在词汇表内的低频词,则替换为\"unk\"\n",
    "def get_id(word):\n",
    "    return word_to_id[word] if word in word_to_id else word_to_id[\"<unk>\"]\n",
    "\n",
    "\n",
    "fin = codecs.open(RAW_DATA, \"r\", \"utf-8\")\n",
    "fout = codecs.open(OUTPUT_DATA, 'w', 'utf-8')\n",
    "for line in fin:\n",
    "    words = line.strip().split() + [\"<eos>\"]  # 读取单词并添加<eos>结束符\n",
    "    # 将每个单词替换为词汇表中的编号\n",
    "    out_line = ' '.join([str(get_id(w)) for w in words]) + '\\n'\n",
    "    fout.write(out_line)\n",
    "fin.close()\n",
    "fout.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### PTB数据的BATCHING\n",
    "- 该数据集不大，一次行读入内存\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiazhuo/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jiazhuo/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jiazhuo/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jiazhuo/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jiazhuo/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jiazhuo/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "TRAIN_DATA=\"data/simple-examples/data/ptb.train\"\n",
    "TRAIN_BATCH_SIZE=20\n",
    "TRAIN_NUM_STEP=35\n",
    "\n",
    "#从文件中读取数据，并返回包含单词编号的数组\n",
    "def read_data(file_path):\n",
    "    with open(file_path,'r') as fin:\n",
    "        #将整个文档读进一个长字符串\n",
    "        id_string=' '.join([line.strip() for line in fin.readlines() ])\n",
    "    #将读取到的编号转换为整数\n",
    "    id_list=[int(w) for w in id_string.split()]\n",
    "    return id_list\n",
    "\n",
    "def make_batch(id_list,batch_size,num_step):\n",
    "    #计算总的batch数量，每个batch包含的单词数量是batch_size*num_step\n",
    "    num_batches=(len(id_list)-1)//(batch_size*num_step)\n",
    "\n",
    "    data=np.array(id_list[:num_batches*batch_size*num_step])\n",
    "    data=np.reshape(data,[batch_size,num_batches*num_step])\n",
    "    data_batches=np.split(data,num_batches,axis=1)\n",
    "\n",
    "    lable=np.array(id_list[1:num_batches*batch_size*num_step+1])\n",
    "    lable=np.reshape(data,[batch_size,num_batches*num_step])\n",
    "    lable_batches=np.split(data,num_batches,axis=1)\n",
    "\n",
    "    return list(zip(data_batches,lable_batches))\n",
    "def main():\n",
    "    train_batches=make_batch(read_data(TRAIN_DATA),TRAIN_BATCH_SIZE,TRAIN_NUM_STEP)\n",
    "\n",
    "if __name__=='main':\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}